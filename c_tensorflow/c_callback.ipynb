{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd672646-fdc6-4747-9df1-5ec49dd872a1",
   "metadata": {},
   "source": [
    "### Callback API\n",
    "- 모델이 학습 중에 충돌이 발생하거나 네트워크가 끊기면, 모든 훈련 시간이 낭비될 수 있고,  \n",
    "  과적합을 방지하기 위해 훈련을 중간에 중지해야 할 수도 있다.\n",
    "- 모델이 학습을 시작하면 학습이 완료될 때까지 아무런 제어를 하지 못하게 되고,  \n",
    "  신경망 훈련을 완료하는 데에는 몇 시간 또는 며칠이 걸릴 수 있기 때문에 모델을 모니터링하고 제어할 수 있는 기능이 필요하다.\n",
    "- 훈련 시(fit()) Callback API를 등록시키면 반복 내에서 특정 이벤트 발생마다 등록된 callback이 호출되어 수행된다.\n",
    "\n",
    "**ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weight_only=False, mode='auto')**\n",
    "- 특정 조건에 따라서 모델 또는 가중치를 파일로 저장한다.\n",
    "- filepath: \"weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.hdf5\"와 같이 모델의 체크포인트를 저장한다.\n",
    "- monitor: 모니터링할 성능 지표를 작성한다.\n",
    "- save_best_only: 가장 좋은 성능을 나타내는 모델을 저장할 지에 대한 여부\n",
    "- save_weights_only: weights만 저장할 지에 대한 여부\n",
    "- mode: {auto, min, max} 중 한 가지를 작성한다. monitor의 성능 지표에 따라 좋은 경우를 선택한다.  \n",
    "  *monitor의 성능 지표가 감소해야 좋은 경우 min, 증가해야 좋은 경우 max, monitor의 이름으로부터 자동으로 유추하고 싶다면 auto\n",
    "\n",
    "\n",
    "**ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_lr=0)**\n",
    "- 특정 반복동안 성능이 개선되지 않을 때, 학습률을 동적으로 감소시킨다.\n",
    "- monitor: 모니터링할 성능 지표를 작성한다.\n",
    "- factor: 학습률을 감소시킬 비율, 새로운 학습률 = 기존 학습률 * factor\n",
    "- patience: 학습률을 줄이기 전에 monitor할 반복 횟수\n",
    "- mode: {auto, min, max} 중 한 가지를 작성한다. monitor의 성능 지표에 따라 좋은 경우를 선택한다.  \n",
    "  *monitor의 성능 지표가 감소해야 좋은 경우 min, 증가해야 좋은 경우 max, monitor의 이름으로부터 자동으로 유추하고 싶다면 auto\n",
    "\n",
    "\n",
    "**EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')**\n",
    "- 특정 반복동안 성능이 개선되지 않을 때, 학습을 조기에 중단한다.\n",
    "- monitor: 모니터링할 성능 지표를 작성한다.\n",
    "- patience: Early Stopping을 적용하기 전에 monitor할 반복 횟수.\n",
    "- mode: {auto, min, max} 중 한 가지를 작성한다. monitor의 성능 지표에 따라 좋은 경우를 선택한다.  \n",
    "  *monitor의 성능 지표가 감소해야 좋은 경우 min, 증가해야 좋은 경우 max, monitor의 이름으로부터 자동으로 유추하고 싶다면 auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ef30c79-19a0-4f8a-837c-7cf753d0f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "INPUT_SIZE = 28\n",
    "\n",
    "def create_model():\n",
    "    input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE))\n",
    "    x = Flatten()(input_tensor)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bde130f-594e-4657-a88c-ccdebee00bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def get_preprocessed_data(images, targets):\n",
    "    images = np.array(images / 255.0, dtype=np.float32)\n",
    "    targets = np.array(targets, dtype=np.float32)\n",
    "\n",
    "    return images, targets\n",
    "\n",
    "def get_preprocessed_ohe(images, targets):\n",
    "    images, targets = get_preprocessed_data(images, targets)\n",
    "    oh_targets = to_categorical(targets)\n",
    "\n",
    "    return images, oh_targets\n",
    "\n",
    "def get_train_valid_test(train_images, train_targets, test_images, test_targets, validation_size=0.2, random_state=124):\n",
    "    train_images, train_oh_targets = get_preprocessed_ohe(train_images, train_targets)\n",
    "    test_images, test_oh_targets = get_preprocessed_ohe(test_images, test_targets)\n",
    "\n",
    "    train_images, validation_images, train_oh_targets, validation_oh_targets = \\\n",
    "    train_test_split(train_images, train_oh_targets, stratify=train_oh_targets, test_size=validation_size, random_state=random_state)\n",
    "\n",
    "    return (train_images, train_oh_targets), (validation_images, validation_oh_targets), (test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f08f5354-1d42-41a3-925a-6f36a952c97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28) (48000, 10)\n",
      "(12000, 28, 28) (12000, 10)\n",
      "(10000, 28, 28) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(train_images, train_targets), (test_images, test_targets) = fashion_mnist.load_data()\n",
    "\n",
    "(train_images, train_oh_targets), (validation_images, validation_oh_targets), (test_images, test_oh_targets) = \\\n",
    "get_train_valid_test(train_images, train_targets, test_images, test_targets)\n",
    "\n",
    "print(train_images.shape, train_oh_targets.shape)\n",
    "print(validation_images.shape, validation_oh_targets.shape)\n",
    "print(test_images.shape, test_oh_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f463df61-a4aa-41af-9692-65baa1fc2fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " D 드라이브의 볼륨: 새 볼륨\n",
      " 볼륨 일련 번호: B6CD-1218\n",
      "\n",
      " D:\\KDT_0900_dkh\\ai\\deep_learning\\c_tensorflow\\callback_files 디렉터리\n",
      "\n",
      "2024-05-27  오후 01:25    <DIR>          .\n",
      "2024-05-29  오전 08:12    <DIR>          ..\n",
      "               0개 파일                   0 바이트\n",
      "               2개 디렉터리  733,247,246,336 바이트 남음\n"
     ]
    }
   ],
   "source": [
    "!dir callback_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ff9ffd-4771-41fc-9f0d-a0476a5fe773",
   "metadata": {},
   "source": [
    "### ModelCheckPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a11f56e-1e2a-42a1-9413-61aa60505104",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.7430 - loss: 0.7523 - val_acc: 0.8502 - val_loss: 0.4167\n",
      "Epoch 2/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - acc: 0.8524 - loss: 0.4090 - val_acc: 0.8577 - val_loss: 0.3892\n",
      "Epoch 3/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690us/step - acc: 0.8700 - loss: 0.3561 - val_acc: 0.8709 - val_loss: 0.3514\n",
      "Epoch 4/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - acc: 0.8766 - loss: 0.3329 - val_acc: 0.8727 - val_loss: 0.3437\n",
      "Epoch 5/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 784us/step - acc: 0.8869 - loss: 0.3079 - val_acc: 0.8696 - val_loss: 0.3521\n",
      "Epoch 6/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - acc: 0.8961 - loss: 0.2862 - val_acc: 0.8749 - val_loss: 0.3385\n",
      "Epoch 7/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - acc: 0.8930 - loss: 0.2889 - val_acc: 0.8703 - val_loss: 0.3410\n",
      "Epoch 8/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - acc: 0.9008 - loss: 0.2677 - val_acc: 0.8832 - val_loss: 0.3296\n",
      "Epoch 9/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690us/step - acc: 0.9046 - loss: 0.2608 - val_acc: 0.8801 - val_loss: 0.3283\n",
      "Epoch 10/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769us/step - acc: 0.9105 - loss: 0.2421 - val_acc: 0.8797 - val_loss: 0.3255\n",
      "Epoch 11/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - acc: 0.9126 - loss: 0.2390 - val_acc: 0.8836 - val_loss: 0.3283\n",
      "Epoch 12/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - acc: 0.9134 - loss: 0.2347 - val_acc: 0.8822 - val_loss: 0.3224\n",
      "Epoch 13/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - acc: 0.9149 - loss: 0.2304 - val_acc: 0.8841 - val_loss: 0.3297\n",
      "Epoch 14/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - acc: 0.9182 - loss: 0.2165 - val_acc: 0.8838 - val_loss: 0.3265\n",
      "Epoch 15/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 745us/step - acc: 0.9181 - loss: 0.2149 - val_acc: 0.8851 - val_loss: 0.3342\n",
      "Epoch 16/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - acc: 0.9240 - loss: 0.2039 - val_acc: 0.8875 - val_loss: 0.3230\n",
      "Epoch 17/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - acc: 0.9266 - loss: 0.2012 - val_acc: 0.8750 - val_loss: 0.3524\n",
      "Epoch 18/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 686us/step - acc: 0.9257 - loss: 0.1984 - val_acc: 0.8911 - val_loss: 0.3202\n",
      "Epoch 19/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - acc: 0.9284 - loss: 0.1879 - val_acc: 0.8842 - val_loss: 0.3376\n",
      "Epoch 20/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - acc: 0.9317 - loss: 0.1866 - val_acc: 0.8855 - val_loss: 0.3500\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "# mcp_cb = ModelCheckpoint(\n",
    "#     filepath=\"./callback_files/weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.h5\",\n",
    "#     monitor='val_loss',\n",
    "#     # 모든 epoch의 파일을 저장하지 않고 좋은 성능이라 판단될 경우만 저장할 때 True설정\n",
    "#     save_best_only=False,\n",
    "#     save_weights_only=True,\n",
    "#     mode='min'\n",
    "# )\n",
    "\n",
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath=\"./callback_files/model.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.model.keras\",\n",
    "    monitor='val_loss',\n",
    "    # 모든 epoch의 파일을 저장하지 않고 좋은 성능이라 판단될 경우만 저장할 때 True설정\n",
    "    save_best_only=False,\n",
    "    save_weights_only=False,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "history = model.fit(x=train_images, y=train_oh_targets, validation_data=(validation_images, validation_oh_targets), batch_size=64, epochs=20, callbacks=[mcp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bd4edbb-267c-4989-adbf-b98674e7cc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " D 드라이브의 볼륨: 새 볼륨\n",
      " 볼륨 일련 번호: B6CD-1218\n",
      "\n",
      " D:\\KDT_0900_dkh\\ai\\deep_learning\\c_tensorflow\\callback_files 디렉터리\n",
      "\n",
      "2024-05-29  오전 08:13    <DIR>          .\n",
      "2024-05-29  오전 08:12    <DIR>          ..\n",
      "2024-05-29  오전 08:13           739,600 weights.001-0.4016-0.8085.weights.h5\n",
      "2024-05-29  오전 08:13           739,600 weights.002-0.3736-0.8608.weights.h5\n",
      "2024-05-29  오전 08:13           739,600 weights.003-0.3669-0.8731.weights.h5\n",
      "2024-05-29  오전 08:13           739,600 weights.004-0.3357-0.8817.weights.h5\n",
      "2024-05-29  오전 08:13           739,600 weights.005-0.3419-0.8871.weights.h5\n",
      "2024-05-29  오전 08:13           739,600 weights.006-0.3258-0.8912.weights.h5\n",
      "2024-05-29  오전 08:13           739,600 weights.007-0.3230-0.8955.weights.h5\n",
      "2024-05-29  오전 08:13           739,600 weights.008-0.3355-0.8995.weights.h5\n",
      "2024-05-29  오전 08:13           739,600 weights.009-0.3161-0.9033.weights.h5\n",
      "2024-05-29  오전 08:13           739,600 weights.010-0.3123-0.9075.weights.h5\n",
      "2024-05-29  오전 08:13           739,600 weights.011-0.3226-0.9088.weights.h5\n",
      "2024-05-29  오전 08:13           739,600 weights.012-0.3068-0.9119.weights.h5\n",
      "2024-05-29  오전 08:13           739,600 weights.013-0.3243-0.9150.weights.h5\n",
      "2024-05-29  오전 08:13           739,600 weights.014-0.3271-0.9177.weights.h5\n",
      "2024-05-29  오전 08:13           739,600 weights.015-0.3260-0.9209.weights.h5\n",
      "2024-05-29  오전 08:13           739,600 weights.016-0.3064-0.9243.weights.h5\n",
      "2024-05-29  오전 08:13           739,600 weights.017-0.3254-0.9249.weights.h5\n",
      "2024-05-29  오전 08:13           739,600 weights.018-0.3416-0.9280.weights.h5\n",
      "2024-05-29  오전 08:13           739,600 weights.019-0.3503-0.9298.weights.h5\n",
      "2024-05-29  오전 08:13           739,600 weights.020-0.3222-0.9302.weights.h5\n",
      "              20개 파일          14,792,000 바이트\n",
      "               2개 디렉터리  733,232,414,720 바이트 남음\n"
     ]
    }
   ],
   "source": [
    "!dir callback_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e194dd8-c6b2-454e-b054-043ed65cbfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - acc: 0.8864 - loss: 0.3598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.362560898065567, 0.885699987411499]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2506fdd-c490-4f82-9bfc-3c623868d702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - acc: 0.8864 - loss: 0.3598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.362560898065567, 0.885699987411499]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.load_weights('./callback_files/weights.020-0.3222-0.9302.weights.h5')\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93d6aaa1-0516-4ca6-acce-aa4c754c0f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - acc: 0.8766 - loss: 0.3975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38855838775634766, 0.8791999816894531]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('./callback_files/model.020-0.3500-0.9309.model.keras')\n",
    "model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c139ef-e649-42cb-a969-7273f4a2f4bf",
   "metadata": {},
   "source": [
    "### ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85fb1808-7981-4c2f-ad38-ce6c6bbdc049",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - acc: 0.7381 - loss: 0.7544 - val_acc: 0.8390 - val_loss: 0.4400 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - acc: 0.8528 - loss: 0.4173 - val_acc: 0.8628 - val_loss: 0.3811 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - acc: 0.8681 - loss: 0.3652 - val_acc: 0.8689 - val_loss: 0.3533 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - acc: 0.8769 - loss: 0.3401 - val_acc: 0.8777 - val_loss: 0.3372 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - acc: 0.8820 - loss: 0.3224 - val_acc: 0.8784 - val_loss: 0.3320 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - acc: 0.8907 - loss: 0.2986 - val_acc: 0.8790 - val_loss: 0.3265 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - acc: 0.8949 - loss: 0.2845 - val_acc: 0.8798 - val_loss: 0.3228 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - acc: 0.8961 - loss: 0.2776 - val_acc: 0.8822 - val_loss: 0.3227 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - acc: 0.9031 - loss: 0.2604 - val_acc: 0.8832 - val_loss: 0.3162 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step - acc: 0.9032 - loss: 0.2606 - val_acc: 0.8864 - val_loss: 0.3181 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - acc: 0.9099 - loss: 0.2433 - val_acc: 0.8867 - val_loss: 0.3186 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step - acc: 0.9217 - loss: 0.2113 - val_acc: 0.8943 - val_loss: 0.2928 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - acc: 0.9267 - loss: 0.2005 - val_acc: 0.8918 - val_loss: 0.2977 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - acc: 0.9291 - loss: 0.1924 - val_acc: 0.8945 - val_loss: 0.2919 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - acc: 0.9284 - loss: 0.1926 - val_acc: 0.8928 - val_loss: 0.2944 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - acc: 0.9286 - loss: 0.1904 - val_acc: 0.8962 - val_loss: 0.2961 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - acc: 0.9309 - loss: 0.1897 - val_acc: 0.8963 - val_loss: 0.2924 - learning_rate: 1.0000e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - acc: 0.9322 - loss: 0.1861 - val_acc: 0.8965 - val_loss: 0.2920 - learning_rate: 1.0000e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683us/step - acc: 0.9328 - loss: 0.1849 - val_acc: 0.8967 - val_loss: 0.2919 - learning_rate: 1.0000e-06\n",
      "Epoch 20/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - acc: 0.9320 - loss: 0.1866 - val_acc: 0.8967 - val_loss: 0.2919 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "history = model.fit(x=train_images, y=train_oh_targets, validation_data=(validation_images, validation_oh_targets), batch_size=64, epochs=20, callbacks=[rlr_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83170c4-fb33-474a-a260-d52b24d63b95",
   "metadata": {},
   "source": [
    "### EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27a725f2-daf0-4516-8efa-a630aa3e0bd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910us/step - acc: 0.7348 - loss: 0.7706 - val_acc: 0.8421 - val_loss: 0.4211\n",
      "Epoch 2/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - acc: 0.8567 - loss: 0.4039 - val_acc: 0.8618 - val_loss: 0.3747\n",
      "Epoch 3/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - acc: 0.8697 - loss: 0.3598 - val_acc: 0.8706 - val_loss: 0.3547\n",
      "Epoch 4/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - acc: 0.8774 - loss: 0.3383 - val_acc: 0.8729 - val_loss: 0.3440\n",
      "Epoch 5/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - acc: 0.8842 - loss: 0.3126 - val_acc: 0.8766 - val_loss: 0.3360\n",
      "Epoch 6/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - acc: 0.8926 - loss: 0.2921 - val_acc: 0.8808 - val_loss: 0.3204\n",
      "Epoch 7/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - acc: 0.8927 - loss: 0.2856 - val_acc: 0.8753 - val_loss: 0.3376\n",
      "Epoch 8/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - acc: 0.8984 - loss: 0.2707 - val_acc: 0.8784 - val_loss: 0.3359\n",
      "Epoch 9/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - acc: 0.9000 - loss: 0.2664 - val_acc: 0.8782 - val_loss: 0.3239\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "history = model.fit(x=train_images, y=train_oh_targets, validation_data=(validation_images, validation_oh_targets), batch_size=64, epochs=20, callbacks=[ely_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aaeb9f05-d839-4d2a-b101-73645675b5aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 954us/step - acc: 0.7454 - loss: 0.7464 - val_acc: 0.8481 - val_loss: 0.4122 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - acc: 0.8585 - loss: 0.3966 - val_acc: 0.8653 - val_loss: 0.3720 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - acc: 0.8704 - loss: 0.3545 - val_acc: 0.8713 - val_loss: 0.3499 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - acc: 0.8800 - loss: 0.3278 - val_acc: 0.8748 - val_loss: 0.3424 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - acc: 0.8865 - loss: 0.3090 - val_acc: 0.8624 - val_loss: 0.3662 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - acc: 0.8895 - loss: 0.2972 - val_acc: 0.8752 - val_loss: 0.3473 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - acc: 0.9054 - loss: 0.2563 - val_acc: 0.8860 - val_loss: 0.3072 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - acc: 0.9108 - loss: 0.2434 - val_acc: 0.8863 - val_loss: 0.3097 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - acc: 0.9130 - loss: 0.2404 - val_acc: 0.8888 - val_loss: 0.3049 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - acc: 0.9136 - loss: 0.2379 - val_acc: 0.8885 - val_loss: 0.3050 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 746us/step - acc: 0.9133 - loss: 0.2352 - val_acc: 0.8900 - val_loss: 0.3030 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 686us/step - acc: 0.9141 - loss: 0.2342 - val_acc: 0.8888 - val_loss: 0.3021 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - acc: 0.9158 - loss: 0.2281 - val_acc: 0.8881 - val_loss: 0.3040 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - acc: 0.9155 - loss: 0.2308 - val_acc: 0.8890 - val_loss: 0.3039 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - acc: 0.9185 - loss: 0.2259 - val_acc: 0.8894 - val_loss: 0.3000 - learning_rate: 1.0000e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - acc: 0.9196 - loss: 0.2206 - val_acc: 0.8900 - val_loss: 0.2995 - learning_rate: 1.0000e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - acc: 0.9196 - loss: 0.2211 - val_acc: 0.8898 - val_loss: 0.2996 - learning_rate: 1.0000e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - acc: 0.9200 - loss: 0.2194 - val_acc: 0.8898 - val_loss: 0.2994 - learning_rate: 1.0000e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - acc: 0.9211 - loss: 0.2176 - val_acc: 0.8904 - val_loss: 0.2994 - learning_rate: 1.0000e-06\n",
      "Epoch 20/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 774us/step - acc: 0.9208 - loss: 0.2185 - val_acc: 0.8903 - val_loss: 0.2994 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath=\"./callback_files/weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.h5\",\n",
    "    monitor='val_loss',\n",
    "    # 모든 epoch의 파일을 저장하지 않고 좋은 성능이라 판단될 경우만 저장할 때 True설정\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "history = model.fit(x=train_images, y=train_oh_targets, validation_data=(validation_images, validation_oh_targets), batch_size=64, epochs=20, callbacks=[mcp_cb, rlr_cb, ely_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb3ce7-eff0-4313-8a10-1873031dad60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
